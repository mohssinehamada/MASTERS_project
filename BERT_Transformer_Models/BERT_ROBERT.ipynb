{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d700421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337a1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68621bc2-0fa9-4fd5-bc66-37ea32e2f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_train = pd.read_csv(\"train.tsv\", sep=\"\\t\", header=None)\n",
    "data_valid = pd.read_csv(\"valid.tsv\", sep=\"\\t\", header=None)    \n",
    "data_test = pd.read_csv(\"test.tsv\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0fe50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953b2ba8-e077-4ebf-be26-8e95f342ae00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1                                                  2   \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                   3               4                     5   \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "         6           7     8     9      10     11    12                   13  \n",
       "0     Texas  republican   0.0   1.0    0.0    0.0   0.0             a mailer  \n",
       "1  Virginia    democrat   0.0   0.0    1.0    1.0   0.0      a floor speech.  \n",
       "2  Illinois    democrat  70.0  71.0  160.0  163.0   9.0               Denver  \n",
       "3       NaN        none   7.0  19.0    3.0    5.0  44.0       a news release  \n",
       "4   Florida    democrat  15.0   9.0   20.0   19.0   2.0  an interview on CNN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99824ab7-bac8-4d15-8943-08b5eed7dfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11972.json</td>\n",
       "      <td>true</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>immigration</td>\n",
       "      <td>rick-perry</td>\n",
       "      <td>Governor</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>Radio interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11685.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>katrina-shankland</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a news conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11096.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>military,veterans,voting-record</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "      <td>63</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>comments on ABC's This Week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5209.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
       "      <td>rob-cornilles</td>\n",
       "      <td>consultant</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a radio show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9524.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "      <td>state-democratic-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>a web video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1                                                  2   \\\n",
       "0  11972.json        true  Building a wall on the U.S.-Mexico border will...   \n",
       "1  11685.json       false  Wisconsin is on pace to double the number of l...   \n",
       "2  11096.json       false  Says John McCain has done nothing to help the ...   \n",
       "3   5209.json   half-true  Suzanne Bonamici supports a plan that will cut...   \n",
       "4   9524.json  pants-fire  When asked by a reporter whether hes at the ce...   \n",
       "\n",
       "                                                  3   \\\n",
       "0                                        immigration   \n",
       "1                                               jobs   \n",
       "2                    military,veterans,voting-record   \n",
       "3  medicare,message-machine-2012,campaign-adverti...   \n",
       "4  campaign-finance,legal-issues,campaign-adverti...   \n",
       "\n",
       "                                 4                     5          6   \\\n",
       "0                        rick-perry              Governor      Texas   \n",
       "1                 katrina-shankland  State representative  Wisconsin   \n",
       "2                      donald-trump       President-Elect   New York   \n",
       "3                     rob-cornilles            consultant     Oregon   \n",
       "4  state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
       "\n",
       "           7   8    9   10  11  12                            13  \n",
       "0  republican  30   30  42  23  18               Radio interview  \n",
       "1    democrat   2    1   0   0   0             a news conference  \n",
       "2  republican  63  114  51  37  61  comments on ABC's This Week.  \n",
       "3  republican   1    1   3   1   1                  a radio show  \n",
       "4    democrat   5    7   2   2   7                   a web video  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "677e2913-ca0f-422f-9412-cafdb79c3eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12134.json</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>vicky-hartzler</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>an interview with ABC17 News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>obama-birth-certificate,religion</td>\n",
       "      <td>chain-email</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7891.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>campaign-finance,congress,taxes</td>\n",
       "      <td>earl-blumenauer</td>\n",
       "      <td>U.S. representative</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a U.S. Ways and Means hearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8169.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "      <td>poverty</td>\n",
       "      <td>jim-francesconi</td>\n",
       "      <td>Member of the State Board of Higher Education</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>an opinion article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>929.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "      <td>economy,stimulus</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>interview with CBS News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1                                                  2   \\\n",
       "0  12134.json  barely-true  We have less Americans working now than in the...   \n",
       "1    238.json   pants-fire  When Obama was sworn into office, he DID NOT u...   \n",
       "2   7891.json        false  Says Having organizations parading as being so...   \n",
       "3   8169.json    half-true     Says nearly half of Oregons children are poor.   \n",
       "4    929.json    half-true  On attacks by Republicans that various program...   \n",
       "\n",
       "                                 3                4   \\\n",
       "0                      economy,jobs   vicky-hartzler   \n",
       "1  obama-birth-certificate,religion      chain-email   \n",
       "2   campaign-finance,congress,taxes  earl-blumenauer   \n",
       "3                           poverty  jim-francesconi   \n",
       "4                  economy,stimulus     barack-obama   \n",
       "\n",
       "                                              5         6           7   8   \\\n",
       "0                            U.S. Representative  Missouri  republican   1   \n",
       "1                                            NaN       NaN        none  11   \n",
       "2                            U.S. representative    Oregon    democrat   0   \n",
       "3  Member of the State Board of Higher Education    Oregon        none   0   \n",
       "4                                      President  Illinois    democrat  70   \n",
       "\n",
       "   9    10   11   12                             13  \n",
       "0   0    1    0    0   an interview with ABC17 News  \n",
       "1  43    8    5  105                            NaN  \n",
       "2   1    1    1    0  a U.S. Ways and Means hearing  \n",
       "3   1    1    1    0             an opinion article  \n",
       "4  71  160  163    9        interview with CBS News  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac91b32e-63af-4bb7-9256-0586d4efb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(dataset):\n",
    "    # Creating new 'label' column based on column 1\n",
    "    dataset['label'] = [1 if x in [\"true\", \"mostly-true\"] else 0 for x in dataset[1]]\n",
    "    \n",
    "    # Debug: print current columns\n",
    "    print(\"Columns before dropping:\", dataset.columns.tolist())\n",
    "    \n",
    "    # Drop unwanted columns by label (not by position)\n",
    "    dataset = dataset.drop(columns=[0, 1, 8, 9, 10, 11, 12])\n",
    "    \n",
    "    # Process metadata columns\n",
    "    meta = []\n",
    "    for i in range(len(dataset)):\n",
    "        subject = dataset.loc[i, 3] if dataset.loc[i, 3] != 0 else 'None'\n",
    "        speaker = dataset.loc[i, 4] if dataset.loc[i, 4] != 0 else 'None'\n",
    "        job = dataset.loc[i, 5] if dataset.loc[i, 5] != 0 else 'None'\n",
    "        state = dataset.loc[i, 6] if dataset.loc[i, 6] != 0 else 'None'\n",
    "        affiliation = dataset.loc[i, 7] if dataset.loc[i, 7] != 0 else 'None'\n",
    "        context = dataset.loc[i, 13] if dataset.loc[i, 13] != 0 else 'None'\n",
    "        meta.append(f\"{subject} {speaker} {job} {state} {affiliation} {context}\")\n",
    "    \n",
    "    # Add the combined metadata column\n",
    "    dataset['combined_meta'] = meta\n",
    "    # Create 'sentence' by combining metadata with text from column 2\n",
    "    dataset[\"sentence\"] = dataset['combined_meta'].astype(str) + \" \" + dataset[2].astype(str)\n",
    "    \n",
    "    # Now drop the original metadata columns and the temporary 'combined_meta'\n",
    "    dataset = dataset.drop(columns=[2, 3, 4, 5, 6, 7, 13, 'combined_meta'])\n",
    "    \n",
    "    # Drop any remaining rows with null values\n",
    "    dataset = dataset.dropna()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472ddc74-da0b-41a7-bb98-8c177bd5157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before dropping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 'label']\n",
      "Columns before dropping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 'label']\n",
      "Columns before dropping: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 'label']\n"
     ]
    }
   ],
   "source": [
    "data_train = data_preprocessing(data_train)\n",
    "data_valid = data_preprocessing(data_valid)\n",
    "data_test = data_preprocessing(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe8af852-db71-428d-931d-d47dd2c7a445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abortion dwayne-bohac State representative Tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>energy,history,job-accomplishments scott-surov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>foreign-policy barack-obama President Illinois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>health-care blog-posting nan nan none a news r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>economy,jobs charlie-crist nan Florida democra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>1</td>\n",
       "      <td>animals,elections aclu-florida nan Florida non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>1</td>\n",
       "      <td>elections alan-powell nan Georgia republican a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>0</td>\n",
       "      <td>retirement,social-security herman-cain nan Geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>0</td>\n",
       "      <td>florida,foreign-policy jeff-greene nan Florida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>0</td>\n",
       "      <td>health-care,veterans michael-steele chairman o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           sentence\n",
       "0          0  abortion dwayne-bohac State representative Tex...\n",
       "1          0  energy,history,job-accomplishments scott-surov...\n",
       "2          1  foreign-policy barack-obama President Illinois...\n",
       "3          0  health-care blog-posting nan nan none a news r...\n",
       "4          0  economy,jobs charlie-crist nan Florida democra...\n",
       "...      ...                                                ...\n",
       "10235      1  animals,elections aclu-florida nan Florida non...\n",
       "10236      1  elections alan-powell nan Georgia republican a...\n",
       "10237      0  retirement,social-security herman-cain nan Geo...\n",
       "10238      0  florida,foreign-policy jeff-greene nan Florida...\n",
       "10239      0  health-care,veterans michael-steele chairman o...\n",
       "\n",
       "[10240 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308512a5-68f4-4af9-90d3-a9a59cc5700c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>economy,jobs vicky-hartzler U.S. Representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>obama-birth-certificate,religion chain-email n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign-finance,congress,taxes earl-blumenaue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>poverty jim-francesconi Member of the State Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>economy,stimulus barack-obama President Illino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>energy,oil-spill,trade barack-obama President ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1</td>\n",
       "      <td>candidates-biography hillary-clinton President...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1</td>\n",
       "      <td>health-care campaign-defend-america nan Washin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>health-care americans-united-change nan nan no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0</td>\n",
       "      <td>candidates-biography,infrastructure rudy-giuli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           sentence\n",
       "0         0  economy,jobs vicky-hartzler U.S. Representativ...\n",
       "1         0  obama-birth-certificate,religion chain-email n...\n",
       "2         0  campaign-finance,congress,taxes earl-blumenaue...\n",
       "3         0  poverty jim-francesconi Member of the State Bo...\n",
       "4         0  economy,stimulus barack-obama President Illino...\n",
       "...     ...                                                ...\n",
       "1279      0  energy,oil-spill,trade barack-obama President ...\n",
       "1280      1  candidates-biography hillary-clinton President...\n",
       "1281      1  health-care campaign-defend-america nan Washin...\n",
       "1282      0  health-care americans-united-change nan nan no...\n",
       "1283      0  candidates-biography,infrastructure rudy-giuli...\n",
       "\n",
       "[1284 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d792369-a261-45d9-8335-717c7ef38038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>immigration rick-perry Governor Texas republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>jobs katrina-shankland State representative Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>military,veterans,voting-record donald-trump P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>0</td>\n",
       "      <td>education rick-scott Governor Florida republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>0</td>\n",
       "      <td>civil-rights,crime,criminal-justice jay-nixon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>0</td>\n",
       "      <td>bipartisanship,congress,foreign-policy,history...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>0</td>\n",
       "      <td>environment,government-efficiency john-kasich ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>0</td>\n",
       "      <td>state-budget,state-finances,taxes john-burzich...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           sentence\n",
       "0         1  immigration rick-perry Governor Texas republic...\n",
       "1         0  jobs katrina-shankland State representative Wi...\n",
       "2         0  military,veterans,voting-record donald-trump P...\n",
       "3         0  medicare,message-machine-2012,campaign-adverti...\n",
       "4         0  campaign-finance,legal-issues,campaign-adverti...\n",
       "...     ...                                                ...\n",
       "1262      0  education rick-scott Governor Florida republic...\n",
       "1263      0  civil-rights,crime,criminal-justice jay-nixon ...\n",
       "1264      0  bipartisanship,congress,foreign-policy,history...\n",
       "1265      0  environment,government-efficiency john-kasich ...\n",
       "1266      0  state-budget,state-finances,taxes john-burzich...\n",
       "\n",
       "[1267 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3f710b-7929-409a-81cc-16ff19816e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abortion dwayne-bohac State representative Tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>energy,history,job-accomplishments scott-surov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>foreign-policy barack-obama President Illinois...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>health-care blog-posting nan nan none a news r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>economy,jobs charlie-crist nan Florida democra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      0  abortion dwayne-bohac State representative Tex...\n",
       "1      0  energy,history,job-accomplishments scott-surov...\n",
       "2      1  foreign-policy barack-obama President Illinois...\n",
       "3      0  health-care blog-posting nan nan none a news r...\n",
       "4      0  economy,jobs charlie-crist nan Florida democra..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330615c5-c819-4da0-88ca-2ecc975b4210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6602\n",
       "1    3638\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc3d2c17-bc57-49eb-bd2d-317e4b5e3d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    864\n",
       "1    420\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "353cf47b-1d7b-436d-a749-c6aeb6aad55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    818\n",
       "1    449\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a51ca6ae-73ba-40e1-a33d-4e1b8027ed77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_len = [] \n",
    "for sent in data_train[\"sentence\"]:\n",
    "    sent_len.append(len(sent))\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.boxplot(sent_len)\n",
    "plt.show()\n",
    "\n",
    "sent_len = [i for i in sent_len if i<=500] #Excluding the outliers\n",
    "fig2 = plt.figure(figsize =(10, 7))\n",
    "plt.hist(sent_len, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ef6c74a-a986-4c9c-a11a-44d4402a2896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54d4d6f8-14db-442c-ac5c-799b34dc8f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ba194-a6e9-4290-835f-0ee804933327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "872f0bdb-c2eb-4dd3-a95a-0ccc0a95f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d181916-65f1-4d3c-8a17-584d862adbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5d28c76-d63b-4dc1-ae4e-72bb6965de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40704987-cf33-49be-a2f2-b43351c2b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dd98c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './model_save/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4303f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eac2a0ca-9315-455f-8e41-3926e9990f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())   # Should be False on Mac\n",
    "print(torch.backends.mps.is_available())  # True if using an M1/M2 Mac with proper PyTorch support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e520a-41d5-4cfe-a8f3-668c7634f30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71057060-347a-413a-84f3-477b2390717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base models loaded \n"
     ]
    }
   ],
   "source": [
    "bert_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", #Using BERT base model with an uncased vocab.\n",
    "                                                                num_labels = 2, #number of output labels - 0,1 (binary classification)\n",
    "                                                                output_attentions = False, #model doesnt return attention weights\n",
    "                                                                output_hidden_states = False #model doesnt return hidden states\n",
    "                                                          )\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "\n",
    "bert_model = bert_model.to(\"mps\")\n",
    "\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", #RoBERTa base model\n",
    "                                                                    num_labels = 2,  #number of output labels - 0,1 (binary classification)\n",
    "                                                                    output_attentions = False,  #model doesnt return attention weights\n",
    "                                                                    output_hidden_states = False #model doesnt return hidden states\n",
    "                                                                )\n",
    "\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", do_lower_case=True)\n",
    "\n",
    "bert_model = bert_model.to(\"mps\")\n",
    "print(\"base models loaded \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2eddfd21-e1ce-434b-b5bf-ae6b1c5aa510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "bert_model = bert_model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb739d50-c4ad-40a2-97f0-1f3c7db0c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  abortion dwayne-bohac State representative Texas republican a mailer Says the Annies List political group supports third-trimester abortions on demand.\n",
      "Tokenized BERT:  ['abortion', 'd', '##way', '##ne', '-', 'bo', '##ha', '##c', 'state', 'representative', 'texas', 'republican', 'a', 'mail', '##er', 'says', 'the', 'annie', '##s', 'list', 'political', 'group', 'supports', 'third', '-', 'trim', '##ester', 'abortion', '##s', 'on', 'demand', '.']\n",
      "Token IDs BERT:  [11324, 1040, 4576, 2638, 1011, 8945, 3270, 2278, 2110, 4387, 3146, 3951, 1037, 5653, 2121, 2758, 1996, 8194, 2015, 2862, 2576, 2177, 6753, 2353, 1011, 12241, 20367, 11324, 2015, 2006, 5157, 1012]\n",
      "Tokenized RoBERT:  ['abortion', 'Ġd', 'wayne', '-', 'b', 'oh', 'ac', 'ĠState', 'Ġrepresentative', 'ĠTexas', 'Ġrepublican', 'Ġa', 'Ġmail', 'er', 'ĠSays', 'Ġthe', 'ĠAnn', 'ies', 'ĠList', 'Ġpolitical', 'Ġgroup', 'Ġsupports', 'Ġthird', '-', 'tr', 'imester', 'Ġabortions', 'Ġon', 'Ġdemand', '.']\n",
      "Token IDs RoBERTa:  [27275, 385, 20143, 12, 428, 2678, 1043, 331, 4915, 1184, 37958, 10, 7107, 254, 15674, 5, 3921, 918, 9527, 559, 333, 4548, 371, 12, 4328, 38417, 17600, 15, 1077, 4]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', data_train[\"sentence\"][0])\n",
    "\n",
    "# Split the sentence into tokens - BERT\n",
    "print('Tokenized BERT: ', bert_tokenizer.tokenize(data_train[\"sentence\"][0]))\n",
    "\n",
    "# Mapping tokens to token IDs - BERT\n",
    "print('Token IDs BERT: ', bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(data_train[\"sentence\"][0])))\n",
    "\n",
    "# Split the sentence into tokens -RoBERTa\n",
    "print('Tokenized RoBERT: ', roberta_tokenizer.tokenize(data_train[\"sentence\"][0]))\n",
    "\n",
    "# Mapping tokens to token IDs - RoBERTa\n",
    "print('Token IDs RoBERTa: ', roberta_tokenizer.convert_tokens_to_ids(roberta_tokenizer.tokenize(data_train[\"sentence\"][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a5ec105-b20e-4f25-939c-0fbca7f3a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data_train[\"sentence\"].values \n",
    "labels = data_train[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e320b33-9b00-44fa-9006-6c2fd1ae6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b5bbfe5-4ffb-4b6b-8178-f438edf67e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below function performs tokenization process as required by bert and roberta models, for a given dataset\n",
    "def bert_robert_tokenization(dataset):\n",
    "  sentences = dataset[\"sentence\"].values\n",
    "  labels = dataset[\"label\"].values\n",
    "  max_length = 256\n",
    "\n",
    "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "  bert_input_ids = []\n",
    "  bert_attention_masks = []\n",
    "  roberta_input_ids = []\n",
    "  roberta_attention_masks = []\n",
    "\n",
    "  sentence_ids = []\n",
    "  counter = 0\n",
    "\n",
    "  # For every sentence...\n",
    "  for sent in sentences:\n",
    "      #encode_plus function will encode the sentences as required by model, including tokenization process and mapping token ids\n",
    "      bert_encoded_dict = bert_tokenizer.encode_plus(\n",
    "                          str(sent),        #sentence              \n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
    "                          max_length = 256,     #Since we have seen from our analysis that majority of sentences have length less than 300.    \n",
    "                          pad_to_max_length = True,    # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
    "                          return_attention_mask = True,   # Create attention mask\n",
    "                          truncation = True,  # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "      \n",
    "      roberta_encoded_dict = roberta_tokenizer.encode_plus(\n",
    "                          str(sent),        #sentence\n",
    "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
    "                          max_length = 256,        #Since we have seen from our analysis that majority of sentences have length less than 300.   \n",
    "                          pad_to_max_length = True,     # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
    "                          return_attention_mask = True,   # Create attention mask\n",
    "                          truncation = True,   # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
    "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                    )\n",
    "      \n",
    "    \n",
    "      # Add the encoded sentence to the list.    \n",
    "      bert_input_ids.append(bert_encoded_dict['input_ids'])\n",
    "      roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n",
    "      \n",
    "      \n",
    "      # Add attention mask to the list \n",
    "      bert_attention_masks.append(bert_encoded_dict['attention_mask'])\n",
    "      roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n",
    "      \n",
    "      \n",
    "      # collecting sentence_ids\n",
    "      sentence_ids.append(counter)\n",
    "      counter  = counter + 1\n",
    "      \n",
    "      \n",
    "      \n",
    "  # Convert the lists into tensors.\n",
    "  bert_input_ids = torch.cat(bert_input_ids, dim=0)\n",
    "  bert_attention_masks = torch.cat(bert_attention_masks, dim=0)\n",
    "\n",
    "  roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n",
    "  roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n",
    "\n",
    "\n",
    "  labels = torch.tensor(labels)\n",
    "  sentence_ids = torch.tensor(sentence_ids)\n",
    "\n",
    "  return {\"Bert\":[bert_input_ids, bert_attention_masks, labels], \"Roberta\":[roberta_input_ids, roberta_attention_masks, labels]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e4cbe44-50bf-46e2-ae49-37e0e4fe879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "# function to seed the script globally\n",
    "torch.manual_seed(0)\n",
    "\n",
    "#tokenizing train set\n",
    "token_dict_train = bert_robert_tokenization(data_train)\n",
    "\n",
    "bert_input_ids,bert_attention_masks,labels = token_dict_train[\"Bert\"]\n",
    "roberta_input_ids, roberta_attention_masks, labels = token_dict_train[\"Roberta\"]\n",
    "\n",
    "#tokenizing validation set\n",
    "token_dict_valid = bert_robert_tokenization(data_valid)\n",
    "\n",
    "bert_input_ids_valid,bert_attention_masks_valid,labels_valid = token_dict_valid[\"Bert\"]\n",
    "roberta_input_ids_valid, roberta_attention_masks_valid, labels_valid = token_dict_valid[\"Roberta\"]\n",
    "\n",
    "#tokenizing test set\n",
    "token_dict_test = bert_robert_tokenization(data_test)\n",
    "\n",
    "bert_input_ids_test,bert_attention_masks_test,labels_test = token_dict_test[\"Bert\"]\n",
    "roberta_input_ids_test, roberta_attention_masks_test, labels_test = token_dict_test[\"Roberta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c7026-85f3-4ed5-9868-fd5dd65bdbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dde78584-cb17-4b30-8845-4157241abef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the teaining , test , validation sapratly  inputs into a tENSORdATASET \n",
    "bert_train_dataset = TensorDataset(bert_input_ids, bert_attention_masks , labels)\n",
    "roberta_train_dataset = TensorDataset(roberta_input_ids , roberta_attention_masks, labels )\n",
    "\n",
    "bert_val_dataset = TensorDataset(bert_input_ids_valid,bert_attention_masks_valid,labels_valid)\n",
    "roberta_val_dataset = TensorDataset(roberta_input_ids_valid, roberta_attention_masks_valid, labels_valid)\n",
    "\n",
    "bert_test_dataset = TensorDataset(bert_input_ids_test,bert_attention_masks_test,labels_test)\n",
    "roberta_test_dataset = TensorDataset(roberta_input_ids_test, roberta_attention_masks_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4b352e1-552a-4d70-a26d-aa74ecd625ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training - Loads the data randomly in batches of size 32\n",
    "bert_train_dataloader = DataLoader(\n",
    "            bert_train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(bert_train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "roberta_train_dataloader = DataLoader(\n",
    "            roberta_train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(roberta_train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# Create the DataLoaders for our validation - Loads the data in batches of size 32\n",
    "bert_validation_dataloader = DataLoader(\n",
    "            bert_val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(bert_val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "\n",
    "roberta_validation_dataloader = DataLoader(\n",
    "            roberta_val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(roberta_val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c10c0c0-6ffd-4203-b9bb-c9117374d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "bert_optimizer = AdamW(bert_model.parameters(),\n",
    "                      lr = 5e-5,\n",
    "                      eps = 1e-8\n",
    ")\n",
    "\n",
    "roberta_optimizer = AdamW(roberta_model.parameters(),\n",
    "                         lr = 5e-5,\n",
    "                         eps = 1e-8\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5f6d94b-6bbd-4d63-8886-a713e5877810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup \n",
    "\n",
    "epochs = 2 \n",
    "\n",
    "total_steps = len(bert_train_dataloader)* epochs\n",
    "\n",
    "bert_scheduler = get_linear_schedule_with_warmup(\n",
    "    bert_optimizer , \n",
    "    num_warmup_steps = 0 ,\n",
    "    num_training_steps= total_steps \n",
    ")\n",
    "roberta_scheduler = get_linear_schedule_with_warmup(\n",
    "    roberta_optimizer,\n",
    "    num_warmup_steps= 0 ,\n",
    "    num_training_steps = total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65cf8328-1ee4-4e64-8bbf-c0ee3a0e1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "#claculating the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np. argmax(preds,axis = 1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68c0942a-6b81-4faf-b162-79e3703b786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import datetime \n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds = elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e3b6b59-a484-480f-a925-63986cf385b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple MPS backend is available. Using the Apple GPU for computations.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Apple MPS backend is available. Using the Apple GPU for computations.\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"There are {torch.cuda.device_count()} GPU(s) available.\")\n",
    "    print(f\"We will use the GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45f0c7e5-643c-4f33-9dd3-c0402d474344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    320.    Elapsed: 0:01:16.\n",
      "  Batch    80  of    320.    Elapsed: 0:02:31.\n",
      "  Batch   120  of    320.    Elapsed: 0:03:45.\n",
      "  Batch   160  of    320.    Elapsed: 0:04:58.\n",
      "  Batch   200  of    320.    Elapsed: 0:06:11.\n",
      "  Batch   240  of    320.    Elapsed: 0:07:29.\n",
      "  Batch   280  of    320.    Elapsed: 0:08:40.\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epcoh took: 0:09:52\n",
      "  Checkpoint saved to ./model_save/checkpoint_epoch_1.pt\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.68\n",
      "  Validation took: 0:00:21\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of    320.    Elapsed: 0:01:13.\n",
      "  Batch    80  of    320.    Elapsed: 0:02:25.\n",
      "  Batch   120  of    320.    Elapsed: 0:03:37.\n",
      "  Batch   160  of    320.    Elapsed: 0:04:48.\n",
      "  Batch   200  of    320.    Elapsed: 0:06:00.\n",
      "  Batch   240  of    320.    Elapsed: 0:07:16.\n",
      "  Batch   280  of    320.    Elapsed: 0:08:29.\n",
      "\n",
      "  Average training loss: 0.57\n",
      "  Training epcoh took: 0:09:43\n",
      "  Checkpoint saved to ./model_save/checkpoint_epoch_2.pt\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.69\n",
      "  Validation took: 0:00:21\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "epochs = 2 \n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    #Training\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "    bert_model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(bert_train_dataloader):\n",
    "      #Report progress after every 40 epochs\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            # print current training batch and elapsed time\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(bert_train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        bert_model.zero_grad()\n",
    "\n",
    "        outputs = bert_model(b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels)\n",
    "\n",
    "        # model returns a tuple, extract loss value from that tuple\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n",
    "        bert_optimizer.step()\n",
    "\n",
    "        bert_scheduler.step()\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(bert_train_dataloader)\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    #Validation Part\n",
    "    checkpoint = {\n",
    "        'epoch': epoch_i + 1,\n",
    "        'model_state_dict': bert_model.state_dict(),\n",
    "        'optimizer_state_dict': bert_optimizer.state_dict(),\n",
    "        'scheduler_state_dict': bert_scheduler.state_dict(),\n",
    "        'loss': avg_train_loss,\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = os.path.join(output_dir, f'checkpoint_epoch_{epoch_i + 1}.pt')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"  Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode\n",
    "    bert_model.eval()\n",
    "    # Tracking variables\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in bert_validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "           outputs = bert_model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36b9ddb9-af03-4789-92ee-7f503079159c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "index=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "xaxis": "x",
         "y": [
          0.6294818043708801,
          0.5665216415189207
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training Loss over Epochs"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epochs"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the training loss over epochs \n",
    "import plotly.express as px \n",
    "f = pd.DataFrame(loss_values)\n",
    "f.columns = ['loss']\n",
    "fig = px.line(f, x = f.index,y=f.loss)\n",
    "fig.update_layout(title = 'Training Loss over Epochs',\n",
    "                  xaxis_title = 'Epochs',\n",
    "                  yaxis_title = 'Loss')\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e43c5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_predictions = SequentialSampler(bert_test_dataset)\n",
    "bert_prediction_dataloader = DataLoader(bert_test_dataset, sampler = bert_predictions, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0258bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictig on 1267 test sentences\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predictig on {len(bert_input_ids_test)} test sentences\")\n",
    "\n",
    "bert_model.eval()\n",
    "\n",
    "predictions , true_labels = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f22f404b-f419-494f-a8f7-b212cf3339f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "for bathc in bert_prediction_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = bert_model(b_input_ids,\n",
    "                             token_type_ids=None,\n",
    "                             attention_mask=b_input_mask)\n",
    "            # Move logits and labels to CPU\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Store predictions and true labels\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "print(\"done\")\n",
    "    # Convert predictions and true labels to numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f898b6dd-e52a-43d4-aea6-0a5248778cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80       120\n",
      "           1       0.50      1.00      0.67        40\n",
      "\n",
      "    accuracy                           0.75       160\n",
      "   macro avg       0.75      0.83      0.73       160\n",
      "weighted avg       0.88      0.75      0.77       160\n",
      "\n",
      "[[80 40]\n",
      " [ 0 40]]\n"
     ]
    }
   ],
   "source": [
    "predictions_labels = [item for subitem in predictions for item in subitem]\n",
    "predictions_labels = np.argmax(predictions_labels , axis = 1).flatten()\n",
    "\n",
    "#combine the correct labels for each bath into a signle list \n",
    "flat_true_labels = [item for subitem in true_labels for item in subitem]\n",
    "\n",
    "from sklearn.metrics import classification_report , confusion_matrix \n",
    "\n",
    "print(classification_report(predictions_labels , flat_true_labels))\n",
    "print(confusion_matrix(predictions_labels , flat_true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838b54c",
   "metadata": {},
   "source": [
    "## training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b458618a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "MPS available: True\n",
      "MPS built: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS built: {torch.backends.mps.is_built()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08907a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Apple Silicon) device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     64\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     66\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(roberta_model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     67\u001b[0m roberta_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    628\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "loss_values = []\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon) device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device\")\n",
    "\n",
    "# Initialize model\n",
    "#roberta_model = RobertaForSequenceClassification.from_pretrained(\n",
    "#    'roberta-base',\n",
    "#    num_labels=2,\n",
    "#    output_attentions=False,\n",
    "#    output_hidden_states=False,\n",
    "#)\n",
    "\n",
    "roberta_model = RobertaForSequenceClassification.from_pretrained(\n",
    "    'distilroberta-base',  # This is a distilled version of RoBERTa, much faster\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "# Optimize batch size\n",
    "batch_size = 16 \n",
    "\n",
    "# Move model to device BEFORE creating optimizer\n",
    "roberta_model = roberta_model.to(device)\n",
    "\n",
    "# Initialize optimizer and scheduler AFTER model is on device\n",
    "optimizer = AdamW(roberta_model.parameters(), lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                          num_warmup_steps=0,\n",
    "                                          num_training_steps=total_steps)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print('')\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    roberta_model.train()\n",
    "\n",
    "    # Add gradient accumulation\n",
    "    accumulation_steps = 4  # Accumulate gradients for 4 steps\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, batch in enumerate(roberta_train_dataloader):\n",
    "        # Move batch to device\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Use mixed precision training\n",
    "        with autocast():\n",
    "            outputs = roberta_model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "            loss = outputs[0]\n",
    "            loss = loss / accumulation_steps  # Normalize loss\n",
    "\n",
    "        # Scale loss and backpropagate\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            # Unscale gradients\n",
    "            scaler.unscale_(optimizer)\n",
    "            # Clip gradients\n",
    "            torch.nn.utils.clip_grad_norm_(roberta_model.parameters(), 1.0)\n",
    "            # Update weights\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(roberta_train_dataloader), elapsed))\n",
    "# For each epoch...\n",
    "#for epoch_i in range(0, epochs):\n",
    "    #print('')\n",
    "    #print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    #print('Training...')\n",
    "\n",
    "    #t0 = time.time()\n",
    "    #total_loss = 0\n",
    "    #roberta_model.train()\n",
    "\n",
    "    #for step, batch in enumerate(roberta_train_dataloader):\n",
    "        # Move batch to device\n",
    "        #b_input_ids = batch[0].to(device)\n",
    "        #b_input_mask = batch[1].to(device)\n",
    "        #b_labels = batch[2].to(device)\n",
    "\n",
    "        #roberta_model.zero_grad()\n",
    "\n",
    "       # outputs = roberta_model(b_input_ids, \n",
    "         #           token_type_ids=None, \n",
    "        #            attention_mask=b_input_mask, \n",
    "       #             labels=b_labels)\n",
    "\n",
    "        # Model returns tuple, extract loss value from that tuple\n",
    "        #loss = outputs[0]\n",
    "\n",
    "        #otal_loss += loss.item()\n",
    "        #loss.backward()\n",
    "       # torch.nn.utils.clip_grad_norm_(roberta_model.parameters(), 1.0)\n",
    "      #  roberta_optimizer.step()\n",
    "\n",
    "     #   roberta_scheduler.step()\n",
    "    # Calculate the average loss over the training data.\n",
    "    #avg_train_loss = total_loss / len(roberta_train_dataloader)\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    \n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # Validation\n",
    "    # Validation optimization\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    roberta_model.eval()\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    with torch.no_grad():  # This ensures no gradients are computed during validation\n",
    "\n",
    "        for batch in roberta_validation_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            with autocast():  # Use mixed precision here too\n",
    "                outputs = roberta_model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1 \n",
    "    \n",
    "    #print(\"\")\n",
    "    #print(\"Running Validation...\")\n",
    "    #t0 = time.time()\n",
    "    # Put the model in evaluation mode\n",
    "    #roberta_model.eval()\n",
    "\n",
    "    #eval_loss, eval_accuracy = 0, 0\n",
    "    #nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Evaluate data for one epoch\n",
    "    #for batch in roberta_validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        #batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "       # b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        #with torch.no_grad():\n",
    "\n",
    "       #     outputs = roberta_model(b_input_ids,\n",
    "       #                     token_type_ids=None,\n",
    "      #                      attention_mask=b_input_mask)\n",
    "\n",
    "\n",
    "     #   logits = outputs[0]\n",
    "        # Move logits and labels to CPU\n",
    "      #  logits = logits.detach().cpu().numpy()\n",
    "     #   label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "    #    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "    #    eval_accuracy += tmp_eval_accuracy\n",
    "        # Track the number of batches\n",
    "    #    nb_eval_steps += 1\n",
    "    # Report the final accuracy for this validation run.\n",
    "    # Optimize your DataLoader\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=train_sampler,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,  # Adjust based on your CPU cores\n",
    "        pin_memory=True  # This helps with faster data transfer to GPU\n",
    "       )\n",
    "    \n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4885693",
   "metadata": {},
   "source": [
    "###Testing Part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65d9b699-661f-4a7d-9913-273730aafd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_prediction_sampler = SequentialSampler(roberta_test_dataset)\n",
    "roberta_prediction_dataloader = DataLoader(roberta_test_dataset, sampler=roberta_prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536ba6e-247a-443f-8b9b-c375f831cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting on {len(roberta_input_ids_test)} test sentences\")\n",
    "\n",
    "roberta_model.eval()\n",
    "\n",
    "predictions, true_labels = [], []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b6eaa-a800-47b0-884f-d09d82b0b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in roberta_prediction_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = roberta_model(b_input_ids,)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a333c3-f4e0-4f77-b47c-6b8f6aef9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_labels = [item for subitem in predictions for item in subitem]\n",
    "predictions_labels = np.argmax(predictions_labels, axis=1).flatten()\n",
    "\n",
    "#combine the correct labels for each batch into a single list\n",
    "flat_true_labels = [item for subitem in true_labels for item in subitem]\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(predictions_labels, flat_true_labels))\n",
    "print(confusion_matrix(predictions_labels, flat_true_labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb0078-2e18-47a4-8e1c-3d846dee064c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa97de7-9bc3-4717-bb76-5ee33dc3f2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858372b0-9711-43e1-8025-2c668604d89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ab90f-afcc-4427-af0d-e7c8fbfe82d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbcc5e1-6dd6-49f6-8f67-4e089ad4f5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4425d-289b-43b0-bece-f878deb0e8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923a99f-adfb-4207-9018-784ff4301f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722d144-e5ff-43f0-8584-6f2fbe24579e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e4664-ac5e-430c-aa6b-fe3fd2deb943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3834a609-f24a-4dee-8e1d-052ced1e1acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b8470-9ad2-4c60-934e-a6807dc170bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15253fe2-75e4-46e3-a262-cc7d52e61f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae32b9-b3b8-4e27-a13a-e3d8f0a0b5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
